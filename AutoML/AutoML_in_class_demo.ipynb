{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Airbnb dataset from Homework 3 to illustrate how different AutoML frameworks work, by doing model selection on the training set and then evaluate on test set. The error metric we are using is balanced error rate, which is the average of false positive rate and false negative rate, and then take the average of those averages across classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import autosklearn.classification\n",
    "from autosklearn.metrics import balanced_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_path = 'oboe/automl/'\n",
    "sys.path.append(automl_path)\n",
    "from auto_learner import AutoLearner\n",
    "import util\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the Airbnb dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_dataset_size = 3000 # number of points to keep in subsampling\n",
    "\n",
    "df_airbnb = pd.read_csv(\"airbnb.csv\", index_col=None, header=0)\n",
    "df_airbnb.drop(df_airbnb[df_airbnb.price == np.nan].index, inplace=True)\n",
    "features_real = [\n",
    "  \"host_listings_count\",\n",
    "  \"host_total_listings_count\",\n",
    "  \"accommodates\",\n",
    "  \"bathrooms\",\n",
    "  \"bedrooms\",\n",
    "  \"guests_included\",\n",
    "  \"extra_people\",\n",
    "  \"minimum_nights\",\n",
    "  \"maximum_nights\",\n",
    "  \"availability_30\",\n",
    "  \"availability_60\",\n",
    "  \"availability_90\",\n",
    "  \"availability_365\",\n",
    "  \"number_of_reviews\",\n",
    "  \"review_scores_rating\",\n",
    "  \"review_scores_accuracy\",\n",
    "  \"review_scores_cleanliness\",\n",
    "  \"review_scores_checkin\",\n",
    "  \"review_scores_communication\",\n",
    "  \"review_scores_location\",\n",
    "  \"price\"\n",
    "]\n",
    "\n",
    "label = [\"review_scores_value\"]\n",
    "x = df_airbnb[features_real].values\n",
    "y = df_airbnb[label].values.flatten()\n",
    "\n",
    "np.random.seed(0)\n",
    "idx_to_keep = np.random.choice(np.arange(y.shape[0]), size=airbnb_dataset_size, replace=False)\n",
    "x = x[idx_to_keep]\n",
    "y = y[idx_to_keep]\n",
    "    \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: auto-sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may restrict the estimator search space to only search for a good classifier among these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_estimators = [\"adaboost\",\"gaussian_nb\", \"extra_trees\", \"gradient_boosting\", \n",
    "                                 \"liblinear_svc\", \"libsvm_svc\",\"random_forest\",\n",
    "                                 \"k_nearest_neighbors\",\"decision_tree\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also specify a running time limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_limit = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A wrapper class for the auto-sklearn learner.\n",
    "def AutoSklearn(total_runtime, train_features, train_labels):\n",
    "    clf = autosklearn.classification.AutoSklearnClassifier(\n",
    "            time_left_for_this_task=total_runtime,\n",
    "            tmp_folder='tmp/autosklearn_tmp_'+str(datetime.now()), \n",
    "            output_folder='tmp/autosklearn_output_'+str(datetime.now()),\n",
    "            metric=balanced_accuracy,\n",
    "            include_estimators = include_estimators,\n",
    "    )\n",
    "        \n",
    "    clf.fit(train_features, train_labels)    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run auto-sklearn for 120 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = 120\n",
    "clf = AutoSklearn(runtime, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predicted training and test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_autosklearn = clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_autosklearn = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show which models the learner has picked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(1.000000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'random_forest', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer', 'feature_preprocessor:__choice__': 'polynomial', 'classifier:random_forest:bootstrap': 'False', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.21794354428393548, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 2, 'classifier:random_forest:min_samples_split': 16, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0025451910134387575, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1477, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform', 'feature_preprocessor:polynomial:degree': 2, 'feature_preprocessor:polynomial:include_bias': 'True', 'feature_preprocessor:polynomial:interaction_only': 'False'},\\ndataset_properties={\\n  'task': 2,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': True,\\n  'target_type': 'classification',\\n  'signed': False})),\\n]\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.show_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the error on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10065950071453614"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.error(y_train, y_train_pred_autosklearn, 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18850923114927096"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.error(y_test, y_test_pred_autosklearn, 'classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: TPOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPOT is an AutoML tool that optimizes machine learning pipelines by genetic programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run TPOT for 120 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681aa82e4f3645c4a8e3dc17a89200a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=20.0, style=ProgressStyle(desâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r",
      "0.58 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\r\n",
      "\r\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\r\n",
      "Best pipeline: DecisionTreeClassifier(SelectFwe(input_matrix, alpha=0.042), criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
       "               disable_update_check=False, early_stop=None, generations=5,\n",
       "               log_file=<ipykernel.iostream.OutStream object at 0x7f26b2870780>,\n",
       "               max_eval_time_mins=5, max_time_mins=0.5, memory=None,\n",
       "               mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
       "               periodic_checkpoint_folder=None, population_size=20,\n",
       "               random_state=None, scoring=None, subsample=1.0, template=None,\n",
       "               use_dask=False, verbosity=2, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=5, population_size=20, verbosity=2, max_time_mins=.5)\n",
    "tpot.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_tpot = tpot.predict(x_train)\n",
    "y_test_pred_tpot = tpot.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the error on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3397069433952885"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tpot training error\n",
    "util.error(y_train, y_train_pred_tpot, 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3557644506500882"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tpot test error\n",
    "util.error(y_test, y_test_pred_tpot, 'classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Oboe (still under development)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oboe Example 1: build an ensemble of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimental settings\n",
    "VERBOSE = False #whether to print out information indicating current fitting progress\n",
    "N_CORES = 1 #number of cores\n",
    "RUNTIME_BUDGET = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional: limit the types of algorithms\n",
    "s = ['AB', 'ExtraTrees', 'GNB', 'KNN', 'RF', 'DT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autolearner arguments\n",
    "autolearner_kwargs = {\n",
    "    'p_type': 'classification',\n",
    "    'runtime_limit': RUNTIME_BUDGET,\n",
    "    'verbose': VERBOSE,\n",
    "    'selection_method': 'min_variance',\n",
    "    'algorithms': s,\n",
    "    'stacking_alg': 'greedy',\n",
    "    'n_cores': N_CORES,\n",
    "    'build_ensemble': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize the autolearner class\n",
    "m = AutoLearner(**autolearner_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit autolearner on training set and record runtime\n",
    "start = time.time()\n",
    "m.fit(x_train, y_train)\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction error: 0.3139487158460067\n",
      "elapsed time: 27.216959714889526\n",
      "individual accuracies of selected models: [0.31651432260061413, 0.32036420549246775, 0.26796126609153437, 0.42171443806106124, 0.31651432260061413]\n"
     ]
    }
   ],
   "source": [
    "# use the fitted autolearner for prediction on test set\n",
    "y_predicted = m.predict(x_test)\n",
    "print(\"prediction error: {}\".format(util.error(y_test, y_predicted, 'classification')))\n",
    "print(\"elapsed time: {}\".format(elapsed_time))\n",
    "print(\"individual accuracies of selected models: {}\".format(m.get_model_accuracy(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ensemble method': 'greedy selection',\n",
       " 'base learners': {'DT': [{'min_samples_split': 0.0001},\n",
       "   {'min_samples_split': 4},\n",
       "   {'min_samples_split': 1024},\n",
       "   {'min_samples_split': 1e-05}],\n",
       "  'GNB': [{}]}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get names of the selected machine learning models\n",
    "m.get_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oboe Example 2: just select a collection of promising models without building an ensemble afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimental settings\n",
    "VERBOSE = False #whether to print out information indicating current fitting progress\n",
    "N_CORES = 1 #number of cores\n",
    "RUNTIME_BUDGET = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional: limit the types of algorithms\n",
    "s = ['AB', 'ExtraTrees', 'GNB', 'KNN', 'RF', 'DT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autolearner arguments\n",
    "autolearner_kwargs = {\n",
    "    'p_type': 'classification',\n",
    "    'runtime_limit': RUNTIME_BUDGET,\n",
    "    'verbose': VERBOSE,\n",
    "    'selection_method': 'min_variance',\n",
    "    'algorithms': s,\n",
    "    'stacking_alg': 'greedy',\n",
    "    'n_cores': N_CORES,\n",
    "    'build_ensemble': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize the autolearner class\n",
    "m = AutoLearner(**autolearner_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit autolearner on training set and record runtime\n",
    "start = time.time()\n",
    "m.fit(x_train, y_train)\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 10.797972679138184\n",
      "accuracies of selected models: [0.31651432260061413, 0.31651432260061413, 0.31651432260061413, 0.31651432260061413, 0.3124772208748183, 0.32036420549246775, 0.35449564337367473, 0.3495441004342578, 0.39048041301086595, 0.26796126609153437, 0.42171443806106124, 0.3001999674360773, 0.3515055898002219, 0.2644854823131578, 0.32215416955204695, 0.31565880270077473, 0.377873248684861, 0.297898906174363]\n"
     ]
    }
   ],
   "source": [
    "# use the fitted autolearner for prediction on test set\n",
    "y_predicted = m.predict(x_test)\n",
    " \n",
    "print(\"elapsed time: {}\".format(elapsed_time))\n",
    "print(\"accuracies of selected models: {}\".format(m.get_model_accuracy(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we do not have a single accuracy value here if we do not build an ensemble, instead, we just have a collection of fitted models with individual accuracies reported.\n",
    "\n",
    "The following shows which models we have picked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DT': [{'min_samples_split': 1e-05},\n",
       "  {'min_samples_split': 1e-05},\n",
       "  {'min_samples_split': 0.0001},\n",
       "  {'min_samples_split': 2},\n",
       "  {'min_samples_split': 0.001},\n",
       "  {'min_samples_split': 4},\n",
       "  {'min_samples_split': 64},\n",
       "  {'min_samples_split': 128},\n",
       "  {'min_samples_split': 256},\n",
       "  {'min_samples_split': 1024},\n",
       "  {'min_samples_split': 8},\n",
       "  {'min_samples_split': 16},\n",
       "  {'min_samples_split': 32},\n",
       "  {'min_samples_split': 0.01}],\n",
       " 'GNB': [{}],\n",
       " 'AB': [{'n_estimators': 50, 'learning_rate': 1},\n",
       "  {'n_estimators': 50, 'learning_rate': 1.5},\n",
       "  {'n_estimators': 100, 'learning_rate': 1}]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
