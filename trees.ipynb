{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#B31B1'> Decision Trees </font>\n",
    "\n",
    "One of the most popular algorithms for classification and regression are decision trees. The underlying idea is simple - we're going to build a set of rules in tree-form to classify a data point. For example, a simple decision tree to predict if you're falling asleep in class could be IF coffee_consumption == 0 THEN asleep_in_class = TRUE ELSE False. They're particularly popular because they're interpretable. (You can see a tree and know exactly how it maps from an input to a decision.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(6,6)}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#B31B1'> Titanic Dataset </font>\n",
    "\n",
    "We are going to use the [Titanic dataset](https://www.kaggle.com/c/titanic/data) for this example. We'll load it directly from the seaborn plotting package.\n",
    "\n",
    "This dataset appears in one of the most basic and popular kaggle competitions: https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town  alone  \n",
       "0    man        True  NaN  Southampton  False  \n",
       "1  woman       False    C    Cherbourg  False  \n",
       "2  woman       False  NaN  Southampton   True  \n",
       "3  woman       False    C  Southampton  False  \n",
       "4    man        True  NaN  Southampton   True  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sns.load_dataset('titanic').drop(['alive'], axis = 1) #Removing some 'cheating' columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>...</th>\n",
       "      <th>deck_A</th>\n",
       "      <th>deck_B</th>\n",
       "      <th>deck_C</th>\n",
       "      <th>deck_D</th>\n",
       "      <th>deck_E</th>\n",
       "      <th>deck_F</th>\n",
       "      <th>deck_G</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass        age  sibsp  parch     fare  adult_male  alone  \\\n",
       "0           0       3  22.000000      1      0   7.2500        True  False   \n",
       "1           1       1  38.000000      1      0  71.2833       False  False   \n",
       "2           1       3  26.000000      0      0   7.9250       False   True   \n",
       "3           1       1  35.000000      1      0  53.1000       False  False   \n",
       "4           0       3  35.000000      0      0   8.0500        True   True   \n",
       "..        ...     ...        ...    ...    ...      ...         ...    ...   \n",
       "886         0       2  27.000000      0      0  13.0000        True   True   \n",
       "887         1       1  19.000000      0      0  30.0000       False   True   \n",
       "888         0       3  29.699118      1      2  23.4500       False  False   \n",
       "889         1       1  26.000000      0      0  30.0000        True   True   \n",
       "890         0       3  32.000000      0      0   7.7500        True   True   \n",
       "\n",
       "     sex_female  sex_male  ...  deck_A  deck_B  deck_C  deck_D  deck_E  \\\n",
       "0             0         1  ...       0       0       0       0       0   \n",
       "1             1         0  ...       0       0       1       0       0   \n",
       "2             1         0  ...       0       0       0       0       0   \n",
       "3             1         0  ...       0       0       1       0       0   \n",
       "4             0         1  ...       0       0       0       0       0   \n",
       "..          ...       ...  ...     ...     ...     ...     ...     ...   \n",
       "886           0         1  ...       0       0       0       0       0   \n",
       "887           1         0  ...       0       1       0       0       0   \n",
       "888           1         0  ...       0       0       0       0       0   \n",
       "889           0         1  ...       0       0       1       0       0   \n",
       "890           0         1  ...       0       0       0       0       0   \n",
       "\n",
       "     deck_F  deck_G  embark_town_Cherbourg  embark_town_Queenstown  \\\n",
       "0         0       0                      0                       0   \n",
       "1         0       0                      1                       0   \n",
       "2         0       0                      0                       0   \n",
       "3         0       0                      0                       0   \n",
       "4         0       0                      0                       0   \n",
       "..      ...     ...                    ...                     ...   \n",
       "886       0       0                      0                       0   \n",
       "887       0       0                      0                       0   \n",
       "888       0       0                      0                       0   \n",
       "889       0       0                      1                       0   \n",
       "890       0       0                      0                       1   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          1  \n",
       "..                       ...  \n",
       "886                        1  \n",
       "887                        1  \n",
       "888                        1  \n",
       "889                        0  \n",
       "890                        0  \n",
       "\n",
       "[891 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We're going to convert our categorical data into 1-Hot Columns \n",
    "#What this does is turns our cateogrical feature data into dummy variables.\n",
    "# have a read of this article - https://www.pluralsight.com/guides/handling-categorical-data-in-machine-learning-models\n",
    "passengers = pd.get_dummies(data)\n",
    "\n",
    "#Fill in NA values for age with the average\n",
    "passengers.age = passengers.age.fillna(passengers.age.mean())\n",
    "\n",
    "#Drop any rows with other misssing valules\n",
    "passengers = passengers.dropna()\n",
    "\n",
    "passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"survived\"\n",
    "features = passengers.drop(columns=label).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#B31B1'> Decision Trees 'Manually' </font>\n",
    "To get some intution for the decision tree algorithm, let's try to find an optimal root-node split for our dataset ourselves. For simplicity, consider a smaller version of our dataset with 2 features: age and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex_male  survived\n",
       "0  22.0         1         0\n",
       "1  38.0         0         1\n",
       "2  26.0         0         1\n",
       "3  35.0         0         1\n",
       "4  35.0         1         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = passengers[['age','sex_male','survived']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have to pick which measure of node purity we want to use - let's use Gini (but try implementing your own cross-entropy function for fun!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(data, feature, split):\n",
    "    \n",
    "    left_node = data[data[feature] > split]\n",
    "    p_left = left_node.survived.mean()\n",
    "    N_left = left_node.shape[0]/data.shape[0]\n",
    "    \n",
    "    right_node = data[data[feature] <= split]\n",
    "    p_right = right_node.survived.mean()\n",
    "\n",
    "    \n",
    "    return N_left*p_left*(1-p_left) + (1-N_left)*p_right*(1-p_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our best split is  sex_male > 0\n"
     ]
    }
   ],
   "source": [
    "best_impurity = np.Inf\n",
    "best_split = None\n",
    "\n",
    "for feature in ['age','sex_male']: # search over features\n",
    "    for s in X[feature].unique():  # search over thresholds\n",
    "        impurity = gini(passengers,feature,s)\n",
    "\n",
    "        if impurity < best_impurity:\n",
    "            best_impurity = impurity\n",
    "            best_split = s\n",
    "            best_split_feature = feature\n",
    "        \n",
    "print('Our best split is ', best_split_feature, '>', best_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can investigate if our split led to a big change in node purity..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.616162\n",
       "1    0.383838\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passengers.survived.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.811092\n",
       "1    0.188908\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passengers.query('sex_male > 0').survived.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.742038\n",
       "0    0.257962\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passengers.query('sex_male <= 0').survived.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    577\n",
       "0    314\n",
       "Name: sex_male, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passengers.sex_male.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like gender is a good split for determining survival rate! We could repeat this process for two new nodes, one with all the male data, one for all the female and so on and so forth..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#B31B1'> Decision Trees in Scikit-Learn </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like most machine learning algorithms, the exceedingly smart people at scikit-learn have implemented decision trees in an optimized version of python called cython. In scikit-learn the tree based algorithms are in the `sklearn.tree` submodule.\n",
    "\n",
    "Scikit-learn tree implementation [uses an optimized version of CART](http://scikit-learn.org/stable/modules/tree.html#tree-algorithms-id3-c4-5-c5-0-and-cart) *(Classification and Regression Trees)*, that allows us to use the decision trees for both classification and regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(passengers[features], passengers.survived)\n",
    "\n",
    "X = passengers[features]\n",
    "Y = passengers.survived\n",
    "\n",
    "tree.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.predict(passengers[features])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of doing one train-test split of our data, we can use **cross-validation** to get an 'average' performance over k splits of our dataset. Scikit-learn does that automaticaly for us using the `cross_val_score` function. Here 'cv' is the parameter to indicate the number of splits. We can even specify what error metric we want to look at (i.e. accuracy vs. AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7755821982298663"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(tree, X, Y,\n",
    "                scoring=\"accuracy\", \n",
    "                cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One very good advantage that decision trees have is that they can be visualized, and we can explain why they take a certain decision  (we say trees have a high **explainability**). Scikit-learn trees can be visualized with `Graphviz`, a graph visualization tool. You can install it using `conda install -c anaconda graphviz` followed by `conda install python-graphviz`.\n",
    "\n",
    "If we have installed graphviz we can plot the tree directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "def draw_tree(tree):\n",
    "    dot_data = export_graphviz(tree, out_file=None, \n",
    "                         feature_names=features, \n",
    "                               class_names=['survived', 'died'],\n",
    "                         filled=True, \n",
    "                         #impurity=True,\n",
    "                         rounded=True,  \n",
    "                         special_characters=True,\n",
    "                              proportion = True)  #trying changing proportion = False\n",
    "    \n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.format = 'png'\n",
    "    graph.render('tree',view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can always check out the help docs\n",
    "DecisionTreeClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the most important hyperparameters for scikit-learn `DecisionTreeClassifier`:\n",
    "\n",
    "Here is a great article that goes over how to understand and potentially use these for tuning your model ... \n",
    "https://towardsdatascience.com/how-to-tune-a-decision-tree-f03721801680\n",
    "\n",
    "\n",
    "* **criterion** : The partition criterion to use, we can use either `gini`, or `entropy` \n",
    "\n",
    "* **max_depth** (int>1) : The max depth the tree can achieve. We define as depth as the number of nodes an observation goes through (how many *questions* are asked).\n",
    "\n",
    "* **max_features** (int or float(percentage)):  The maximum number of potential partitions evaluated when we split a node.\n",
    "\n",
    "* **max_leaf_nodes** (int or None): Max number of leaves in the tree.\n",
    "\n",
    "* **min_impurity_decrease** (float) : The minimum information gain required in a node to split it (if no feature provides that minimum, the node becomes a leaf).\n",
    "\n",
    "* **class_weight** : For imbalanced classes, we can use `class_weight`, which is a dictionary with the shape `{class: weight}`, so sklearn takes the class weights into consideration. We can also use `class_weight=balanced` so sklearn creates the weights automatically based on class distribution.\n",
    "\n",
    "Decision trees are prone to overfitting, there are some hyperparameters that help us control this:\n",
    "\n",
    "* **min_samples_leaf** (int or float(percentage)) : Minimum number of observations on a node to consider the node a leaf. Default value is 1, this means that by default sklearn will create leaves with one observation (and this memorize the dataset).\n",
    "\n",
    "* **min_samples_split** (int or float(percentage)) : Minimum number of observations on a node to generate a partition. By default is 2, this means sklearn will split all nodes with 2 or more observations by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can create a simpler tree by setting the maximum depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_tree = DecisionTreeClassifier(max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=4)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_tree.fit(passengers.drop(\"survived\", axis=1), \n",
    "                 passengers.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_tree(simple_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8452928770012463"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(simple_tree, passengers.drop(\"survived\", axis=1), \n",
    "                passengers.survived, scoring=\"roc_auc\", cv=3).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see this simple tree performs much better than the initial tree (that was overfitting), and it is also very simple to explain!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how do we know what the optimal depth is?\n",
    "\n",
    "Well this is a balance of practicality and \"hyperparameter tuning\" ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perhaps for our business problem anything with greater than depth of 10 is too complicated and don't want to run the risk of overfitting (think of our first tree...)\n",
    "# So let's test a range of depths from 2:10 using a for loop\n",
    "\n",
    "depths = np.arange(2,10) # define the depths\n",
    "results = [] # create an empty data frame for our results\n",
    "\n",
    "for depth in depths:\n",
    "    best_depth_tree = DecisionTreeClassifier(max_depth = depth) # creating an instance of a decision tree\n",
    "    results.append(cross_val_score(best_depth_tree, passengers.drop(\"survived\", axis=1), \n",
    "                                   passengers.survived, scoring=\"roc_auc\", # getting the cv accuracy metric for the tree at each depth\n",
    "                cv=3).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f86a4028af0>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = pd.DataFrame({'depths':depths, 'mean_roc_auc':results})\n",
    "test.sort_values(\"mean_roc_auc\", ascending=False)\n",
    "plt.plot(test.depths, test.mean_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I would now move forward with my model with max_depth set = 3"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
