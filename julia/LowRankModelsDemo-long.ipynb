{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mChecking out LowRankModels master...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPulling LowRankModels latest master...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mNo packages to install, update or remove\n",
      "\u001b[39mWARNING: Method definition ==(Base.Nullable{S}, Base.Nullable{T}) in module Base at nullable.jl:238 overwritten in module NullableArrays at /Users/madeleine/.julia/v0.6/NullableArrays/src/operators.jl:128.\n"
     ]
    }
   ],
   "source": [
    "Pkg.checkout(\"LowRankModels\")\n",
    "using LowRankModels, Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LowRankModels.jl is a julia package for modeling and fitting generalized low rank models (GLRMs). GLRMs model a data array by a low rank matrix, and include many well known models in data analysis, such as principal components analysis (PCA), matrix completion, robust PCA, nonnegative matrix factorization, k-means, and many more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LowRankModels.jl makes it easy to mix and match loss functions and regularizers to construct a model suitable for a particular data set. In particular, it supports\n",
    "\n",
    "   * using different loss functions for different columns of the data array, which is useful when data types are heterogeneous (eg, real, boolean, and ordinal columns);\n",
    "   * fitting the model to only some of the entries in the table, which is useful for data tables with many missing (unobserved) entries; and\n",
    "   * adding offsets and scalings to the model without destroying sparsity, which is useful when the data is poorly scaled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supported losses include:\n",
    "   * quadratic loss - QuadLoss()\n",
    "   * hinge loss - HingeLoss()\n",
    "   * logistic loss - LogisticLoss()\n",
    "   * poisson loss - PoissonLoss()\n",
    "   * weighted hinge loss - WeightedHingeLoss()\n",
    "   * l1 loss - L1Loss()\n",
    "   * ordinal hinge loss - OrdinalHingeLoss()\n",
    "   * periodic loss - PeriodicLoss()\n",
    "   * multinomial categorical loss - MultinomialLoss()\n",
    "   * multinomial ordinal (aka ordered logit) loss - OrderedMultinomialLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: QuadLoss not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: QuadLoss not defined",
      ""
     ]
    }
   ],
   "source": [
    "# loss function\n",
    "loss = QuadLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: evaluate not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: evaluate not defined",
      ""
     ]
    }
   ],
   "source": [
    "# the quad loss returns the sum of square differences between its first and second argument\n",
    "evaluate(loss, 2., 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: evaluate not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: evaluate not defined",
      ""
     ]
    }
   ],
   "source": [
    "# can scale the loss by any factor\n",
    "evaluate(3*loss, 2., 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: evaluate not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: evaluate not defined",
      ""
     ]
    }
   ],
   "source": [
    "evaluate(2*loss, [1., 1.], [3., 3.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: grad not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: grad not defined",
      ""
     ]
    }
   ],
   "source": [
    "# can also evaluate the gradient wrt the first argument\n",
    "grad(loss, 2., 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: grad not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: grad not defined",
      ""
     ]
    }
   ],
   "source": [
    "grad(loss, [2., 0.], [0., 2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: grad not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: grad not defined",
      ""
     ]
    }
   ],
   "source": [
    "grad(L1Loss(), [2., 0.], [0., 2.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supported regularizers include:\n",
    "\n",
    "   * quadratic regularization - QuadReg()\n",
    "   * constrained squared euclidean norm - QuadConstraint()\n",
    "   * l1 regularization - OneReg()\n",
    "   * no regularization - ZeroReg()\n",
    "   * nonnegative constraint - NonNegConstraint() (eg, for nonnegative matrix factorization)\n",
    "   * 1-sparse constraint - OneSparseConstraint() (eg, for orthogonal NNMF)\n",
    "   * unit 1-sparse constraint - UnitOneSparseConstraint() (eg, for k-means)\n",
    "   * simplex constraint - SimplexConstraint()\n",
    "   * l1 regularization, combined with nonnegative constraint - NonNegOneReg()\n",
    "   * fix features at values y0 - FixedLatentFeaturesConstraint(y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: NonNegConstraint not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: NonNegConstraint not defined",
      ""
     ]
    }
   ],
   "source": [
    "# regularizers\n",
    "lambda = 1\n",
    "\n",
    "nonneg = NonNegConstraint()\n",
    "l1 = OneReg(lambda)\n",
    "l2 = QuadReg(lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: prox not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: prox not defined",
      ""
     ]
    }
   ],
   "source": [
    "# can evaluate the proximal operator of the regularizer\n",
    "prox(nonneg, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: prox not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: prox not defined",
      ""
     ]
    }
   ],
   "source": [
    "prox(nonneg, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: prox not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: prox not defined",
      ""
     ]
    }
   ],
   "source": [
    "prox(nonneg, [-5, -1, 0, 1, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: prox not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: prox not defined",
      ""
     ]
    }
   ],
   "source": [
    "# can evaluate the proximal operator of lambda times the regularizer\n",
    "λ = .01\n",
    "prox(l1, 1, λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chain rule: \n",
    "# gradient of ||Xw - y||^2 wrt w is X' * <gradient of ||z-y||^2 wrt z>, \n",
    "# where z = X*w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these to easily run proximal gradient on any combination of loss function and regularizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mINFO: Precompiling module LowRankModels.\n",
      "\u001b[0mWARNING: Method definition describe(AbstractArray) in module StatsBase at /Users/madeleine/.julia/v0.5/StatsBase/src/scalarstats.jl:573 overwritten in module DataFrames at /Users/madeleine/.julia/v0.5/DataFrames/src/abstractdataframe/abstractdataframe.jl:407.\n",
      "\u001b[1m\u001b[31mERROR: LoadError: LoadError: syntax: invalid operator \".!\"\n",
      " in include_from_node1(::String) at ./loading.jl:488\n",
      " in include_from_node1(::String) at /Applications/Julia-0.5.app/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " in include_from_node1(::String) at ./loading.jl:488\n",
      " in include_from_node1(::String) at /Applications/Julia-0.5.app/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " in macro expansion; at ./none:2 [inlined]\n",
      " in anonymous at ./<missing>:?\n",
      " in eval(::Module, ::Any) at ./boot.jl:234\n",
      " in eval(::Module, ::Any) at /Applications/Julia-0.5.app/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      " in process_options(::Base.JLOptions) at ./client.jl:239\n",
      " in _start() at ./client.jl:318\n",
      " in _start() at /Applications/Julia-0.5.app/Contents/Resources/julia/lib/julia/sys.dylib:?\n",
      "while loading /Users/madeleine/.julia/v0.5/LowRankModels/src/scikitlearn.jl, in expression starting on line 56\n",
      "while loading /Users/madeleine/.julia/v0.5/LowRankModels/src/LowRankModels.jl, in expression starting on line 51\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "Failed to precompile LowRankModels to /Users/madeleine/.julia/lib/v0.5/LowRankModels.ji.",
     "output_type": "error",
     "traceback": [
      "Failed to precompile LowRankModels to /Users/madeleine/.julia/lib/v0.5/LowRankModels.ji.",
      "",
      " in compilecache(::String) at ./loading.jl:593",
      " in require(::Symbol) at ./loading.jl:422",
      " in require(::Symbol) at /Applications/Julia-0.5.app/Contents/Resources/julia/lib/julia/sys.dylib:?"
     ]
    }
   ],
   "source": [
    "import LowRankModels: evaluate, grad\n",
    "evaluate(loss::Loss, X::Array{Float64,2}, w, y) = evaluate(loss, X*w, y)\n",
    "grad(loss::Loss, X::Array{Float64,2}, w, y) = X'*grad(loss, X*w, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: Loss not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: Loss not defined",
      ""
     ]
    }
   ],
   "source": [
    "# proximal gradient method\n",
    "function proxgrad(loss::Loss, reg::Regularizer, X, y;\n",
    "                  maxiters::Int = 10, stepsize::Number = 1., \n",
    "                  ch::ConvergenceHistory = ConvergenceHistory(\"proxgrad\"))\n",
    "    w = zeros(size(X,2))\n",
    "    for t=1:maxiters\n",
    "        t0 = time()\n",
    "        # gradient step\n",
    "        g = grad(loss, X, w, y)\n",
    "        w = w - stepsize*g\n",
    "        # prox step\n",
    "        w = prox(reg, w, stepsize)\n",
    "        # record objective value\n",
    "        update_ch!(ch, time() - t0, obj = evaluate(loss, X, w, y) + evaluate(reg, w))\n",
    "    end\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: ConvergenceHistory not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: ConvergenceHistory not defined",
      ""
     ]
    }
   ],
   "source": [
    "srand(0)\n",
    "X, y = rand(6,3), rand(6);\n",
    "ch = ConvergenceHistory(\"NNLS\")\n",
    "w = proxgrad(QuadLoss(), NonNegConstraint(), X, y; \n",
    "             stepsize=.1, maxiters=50,\n",
    "             ch = ch)\n",
    "\n",
    "plot(ch.objective)\n",
    "xlabel(\"iteration\")\n",
    "ylabel(\"objective\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: ch not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: ch not defined",
      ""
     ]
    }
   ],
   "source": [
    "semilogy(ch.objective - ch.objective[end])\n",
    "xlabel(\"iteration\")\n",
    "ylabel(\"objective\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Low Rank Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLRMs form a low rank model for tabular data A with m rows and n columns, which can be input as an array or any array-like object (for example, a data frame). It is fine if only some of the entries have been observed (i.e., the others are missing or NA); the GLRM will only be fit on the observed entries $\\Omega$.\n",
    "\n",
    "The desired model is specified by choosing a rank k for the model, an array of loss functions losses, and two regularizers, $r_x$ and $r_w$. The data is modeled as $X^TW$, where $X$ is a $k\\times m$ matrix and $W$ is a $k\\times n$ matrix. $X$ and $W$ are found by solving the optimization problem\n",
    "\n",
    "$$\\min \\sum_{(i,j) \\in \\Omega} loss_j\\bigg((X^TW)[i,j], Y[i,j]\\bigg) + \\sum_i r_x(X[:,i]) + \\sum_j r_y(W[:,j])$$\n",
    "\n",
    "To form a GLRM, the user specifies\n",
    "\n",
    "   * the data $Y$ (any AbstractArray, such as an array, a sparse matrix, or a data frame)\n",
    "   * the array of loss functions losses\n",
    "   * the regularizers $r_x$ and $r_w$\n",
    "   * the rank $k$\n",
    "   * the observations $\\Omega$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: QuadLoss not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: QuadLoss not defined",
      ""
     ]
    }
   ],
   "source": [
    "# example\n",
    "Y = randn(10, 10)\n",
    "loss = QuadLoss()\n",
    "nonneg = NonNegConstraint()\n",
    "k = 5\n",
    "Ω = [(rand(1:10), rand(1:10)) for iobs in 1:50] # observe 50 random entries, with replacement\n",
    "glrm = GLRM(Y, loss, nonneg, nonneg, k, obs=Ω);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: fit! not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: fit! not defined",
      ""
     ]
    }
   ],
   "source": [
    "# To fit the model, call\n",
    "X,W,ch = fit!(glrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This runs an alternating directions proximal gradient method on glrm to find the $X$ and $W$ minimizing the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×3 Array{Float64,2}:\n",
       " 0.823648  0.0423017  0.260036\n",
       " 0.910357  0.0682693  0.910047\n",
       " 0.164566  0.361828   0.167036\n",
       " 0.177329  0.973216   0.655448\n",
       " 0.27888   0.585812   0.575887\n",
       " 0.203477  0.539289   0.868279"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: W not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: W not defined",
      ""
     ]
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: plot not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: plot not defined",
      ""
     ]
    }
   ],
   "source": [
    "plot(ch.objective)\n",
    "xlabel(\"iteration\")\n",
    "ylabel(\"objective\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The losses argument can also be an array of loss functions, with one for each column (in order). For example, for a data set with 3 columns, you could use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: Loss not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: Loss not defined",
      ""
     ]
    }
   ],
   "source": [
    "losses = Loss[QuadLoss(), LogisticLoss(), HingeLoss()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similiarly, the $r_w$ argument can be an array of regularizers, with one for each column (in order). For example, for a data set with 3 columns, you could use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: Regularizer not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: Regularizer not defined",
      ""
     ]
    }
   ],
   "source": [
    "rw = Regularizer[QuadReg(1), QuadReg(10), OneReg()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_pca (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minimize ||Y - XW||^2\n",
    "function fit_pca(m,n,k)\n",
    "\t# matrix to encode\n",
    "\tY = randn(m,k)*randn(k,n)\n",
    "\tloss = QuadLoss()\n",
    "\tr = ZeroReg()\n",
    "\tglrm = GLRM(Y,loss,r,r,k)\n",
    "\tX,W,ch = fit!(glrm)\n",
    "\tprintln(\"Convergence history:\",ch.objective)\n",
    "\treturn Y,X,W,ch\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
